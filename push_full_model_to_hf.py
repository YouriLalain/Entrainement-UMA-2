#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script pour pusher le MODÃˆLE COMPLET (InternVL2 + tÃªte) sur Hugging Face Hub
"""

import os
import argparse
import shutil
from pathlib import Path
from huggingface_hub import HfApi, create_repo, upload_folder
import yaml


def create_model_card(repo_name, config_path, output_path):
    """CrÃ©e un README.md pour le modÃ¨le"""
    
    # Charge la config
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    classes = config.get('classes', [])
    num_classes = len(classes)
    
    readme_content = f"""---
license: mit
base_model: OpenGVLab/InternVL2-2B
tags:
  - vision
  - object-detection
  - aircraft
  - internvl
  - fine-tuned
language:
  - en
  - fr
pipeline_tag: object-detection
---

# InternVL2-2B Aircraft Parts Detection

ModÃ¨le InternVL2-2B fine-tunÃ© pour la dÃ©tection de {num_classes} parties d'avion.

## ğŸ¯ Description

Ce modÃ¨le est basÃ© sur **InternVL2-2B** (OpenGVLab) et a Ã©tÃ© fine-tunÃ© avec une tÃªte de dÃ©tection personnalisÃ©e pour dÃ©tecter les parties suivantes d'un avion :

{chr(10).join(f"- {i+1}. **{cls}**" for i, cls in enumerate(classes))}

## ğŸ—ï¸ Architecture

```
Image (448x448)
    â†“
InternVL2-2B Vision Encoder (FROZEN)
    â†“
Detection Head (TRAINABLE)
    â”œâ”€â”€ Classification: {num_classes} classes
    â””â”€â”€ Bounding Boxes: (x, y, w, h)
    â†“
ROI Projector (TRAINABLE)
    â†“
Object Tokens â†’ LLM
```

**ParamÃ¨tres entraÃ®nÃ©s** : ~2M (Detection Head + ROI Projector)  
**ParamÃ¨tres frozen** : ~2B (InternVL2-2B)

## ğŸš€ Utilisation

### Installation

```bash
pip install torch torchvision transformers pillow pyyaml
```

### Chargement du modÃ¨le

```python
import torch
from model import load_model
import yaml

# Charge la config
with open("config.yaml", 'r') as f:
    config = yaml.safe_load(f)

# Charge le modÃ¨le complet (InternVL2 + tÃªte)
model = load_model(config)

# Charge les poids de la tÃªte de dÃ©tection
checkpoint = torch.load("detection_weights.pt")
model.detection_head.load_state_dict(checkpoint['detection_head'])
model.roi_projector.load_state_dict(checkpoint['roi_projector'])

model.eval()
```

### InfÃ©rence

```python
from PIL import Image
import torchvision.transforms as transforms

# PrÃ©pare l'image
image = Image.open("aircraft.jpg").convert("RGB")
transform = transforms.Compose([
    transforms.Resize((448, 448)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
image_tensor = transform(image).unsqueeze(0)

# InfÃ©rence
with torch.no_grad():
    outputs = model(image_tensor)
    cls_scores = outputs['cls_scores']
    bbox_preds = outputs['bbox_preds']

# Post-traitement pour extraire les dÃ©tections
# (voir inference.py pour le code complet)
```

## ğŸ“Š Performance

- **Dataset** : {config.get('dataset_description', 'Custom aircraft parts dataset')}
- **Epochs** : {config.get('epochs', 'N/A')}
- **Batch size** : {config.get('batch_size', 'N/A')}
- **Learning rate** : {config.get('learning_rate', 'N/A')}

## ğŸ“ Structure du modÃ¨le

```
.
â”œâ”€â”€ internvl2/              # ModÃ¨le InternVL2-2B complet
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â””â”€â”€ ...
â”œâ”€â”€ detection_weights.pt    # Poids de la tÃªte de dÃ©tection
â”œâ”€â”€ config.yaml            # Configuration d'entraÃ®nement
â””â”€â”€ README.md              # Ce fichier
```

## ğŸ”§ Configuration

```yaml
{yaml.dump(config, default_flow_style=False, allow_unicode=True)}
```

## ğŸ“ Citation

Si vous utilisez ce modÃ¨le, merci de citer :

```bibtex
@misc{{internvl2-aircraft-detection,
  title={{InternVL2-2B Aircraft Parts Detection}},
  author={{Your Name}},
  year={{2025}},
  howpublished={{\\url{{https://huggingface.co/{repo_name}}}}}
}}
```

## ğŸ“„ Licence

MIT License - Voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **InternVL2** par OpenGVLab : [OpenGVLab/InternVL2-2B](https://huggingface.co/OpenGVLab/InternVL2-2B)
- BasÃ© sur l'architecture Vision-Language Model

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue sur le repo.

---

**Note** : Ce modÃ¨le contient le modÃ¨le InternVL2-2B complet (~4.4GB). Si vous voulez seulement les poids de la tÃªte de dÃ©tection (~10MB), utilisez le checkpoint lÃ©ger `checkpoint_best.pt`.
"""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ… Model card crÃ©Ã© : {output_path}")


def push_full_model_to_hf(
    full_model_dir,
    repo_name,
    hf_token=None,
    private=True,
    commit_message="Upload complete InternVL2-2B detection model"
):
    """
    Push le modÃ¨le COMPLET sur Hugging Face Hub
    
    Args:
        full_model_dir: Chemin vers le dossier full_model_best
        repo_name: Nom du repo HF
        hf_token: Token HF
        private: Repo privÃ© ou public
        commit_message: Message de commit
    """
    
    print(f"ğŸš€ Push du MODÃˆLE COMPLET vers Hugging Face Hub...")
    print(f"ğŸ“¦ Dossier: {full_model_dir}")
    print(f"ğŸ·ï¸  Repo: {repo_name}")
    
    full_model_path = Path(full_model_dir)
    
    # VÃ©rifie que le dossier existe
    if not full_model_path.exists():
        raise FileNotFoundError(f"Dossier introuvable: {full_model_dir}")
    
    # RÃ©cupÃ¨re le token
    if hf_token is None:
        hf_token = os.environ.get("HF_TOKEN")
        if hf_token is None:
            raise ValueError("Token Hugging Face requis. Utilisez --token ou HF_TOKEN env var")
    
    # API Hugging Face
    api = HfApi(token=hf_token)
    
    # CrÃ©e le repo (si n'existe pas)
    print(f"ğŸ“ CrÃ©ation du repo '{repo_name}' (si nÃ©cessaire)...")
    try:
        create_repo(
            repo_id=repo_name,
            token=hf_token,
            private=private,
            exist_ok=True
        )
        print("âœ… Repo crÃ©Ã©/trouvÃ©")
    except Exception as e:
        print(f"âš ï¸  Erreur crÃ©ation repo: {e}")
    
    # CrÃ©e le README.md
    config_path = full_model_path.parent.parent / "config.yaml"
    readme_path = full_model_path / "README.md"
    
    if config_path.exists():
        create_model_card(repo_name, config_path, readme_path)
    else:
        print("âš ï¸  config.yaml introuvable, README.md minimal crÃ©Ã©")
        with open(readme_path, 'w') as f:
            f.write(f"# {repo_name}\n\nModÃ¨le InternVL2-2B fine-tunÃ© pour la dÃ©tection d'objets.")
    
    print(f"\nğŸ“¤ Upload des fichiers (cela peut prendre plusieurs minutes pour ~4.4GB)...")
    print("â˜• Allez vous chercher un cafÃ©, Ã§a va prendre un peu de temps...")
    
    # Upload tout le dossier
    try:
        upload_folder(
            folder_path=str(full_model_path),
            repo_id=repo_name,
            token=hf_token,
            commit_message=commit_message,
            ignore_patterns=["*.pyc", "__pycache__", "*.git*"]
        )
        print(f"\nâœ… ModÃ¨le complet uploadÃ© avec succÃ¨s!")
        print(f"ğŸ”— Lien: https://huggingface.co/{repo_name}")
        
        # Instructions pour tÃ©lÃ©charger
        print(f"\nğŸ“¥ Pour tÃ©lÃ©charger le modÃ¨le complet:")
        print(f"   from huggingface_hub import snapshot_download")
        print(f"   snapshot_download(repo_id='{repo_name}', local_dir='./my_model')")
        
    except Exception as e:
        print(f"âŒ Erreur upload: {e}")
        raise


def main():
    parser = argparse.ArgumentParser(description="Push le MODÃˆLE COMPLET sur Hugging Face Hub")
    parser.add_argument(
        "--model-dir",
        type=str,
        required=True,
        help="Chemin vers le dossier full_model_best (ex: experiments/run_XXX/checkpoints/full_model_best)"
    )
    parser.add_argument(
        "--repo",
        type=str,
        required=True,
        help="Nom du repo HF (ex: 'yourusername/model-name')"
    )
    parser.add_argument(
        "--token",
        type=str,
        default=None,
        help="Token Hugging Face (ou utilisez HF_TOKEN env var)"
    )
    parser.add_argument(
        "--public",
        action="store_true",
        help="Rendre le repo public (par dÃ©faut: privÃ©)"
    )
    parser.add_argument(
        "--message",
        type=str,
        default="Upload complete InternVL2-2B detection model",
        help="Message de commit"
    )
    
    args = parser.parse_args()
    
    push_full_model_to_hf(
        full_model_dir=args.model_dir,
        repo_name=args.repo,
        hf_token=args.token,
        private=not args.public,
        commit_message=args.message
    )


if __name__ == "__main__":
    main()
